{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eba234e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,random_split,TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import json\n",
    "import joblib\n",
    "import ast\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97e688aa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_df = pd.read_csv('static_categorical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8624b213",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class StaticOneHotManager:\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "\n",
    "    def fit(self, df, categorical_cols):\n",
    "        for col in categorical_cols:\n",
    "            categories = df[col].dropna().astype(str).unique().tolist()\n",
    "\n",
    "            enc = OneHotEncoder(\n",
    "                sparse_output=False,\n",
    "                handle_unknown=\"ignore\",\n",
    "                categories=[categories]\n",
    "            )\n",
    "            values = df[col].dropna().astype(str).values.reshape(-1, 1)\n",
    "            enc.fit(values)\n",
    "\n",
    "            self.encoders[col] = enc\n",
    "\n",
    "    def transform(self, df, categorical_cols, return_numpy=True):\n",
    "        out = pd.DataFrame()\n",
    "        if \"PATIENT\" in df.columns:\n",
    "            out[\"PATIENT\"] = df[\"PATIENT\"]\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            enc = self.encoders[col]\n",
    "\n",
    "            values = df[col].astype(str).values.reshape(-1, 1)\n",
    "            is_na = df[col].isna().values\n",
    "\n",
    "            encoded = enc.transform(values)\n",
    "\n",
    "            encoded[is_na] = 0\n",
    "            if return_numpy:\n",
    "                out[col] = [encoded[i, :] for i in range(encoded.shape[0])]\n",
    "            else:\n",
    "                out[col] = encoded.tolist()\n",
    "\n",
    "        return out\n",
    "\n",
    "    def inverse_transform(self, series, col):\n",
    "        enc = self.encoders[col]\n",
    "        categories = enc.categories_[0]  \n",
    "        results = []\n",
    "    \n",
    "        for arr in series:\n",
    "            arr = np.array(arr, dtype=float)  \n",
    "            if arr.sum() == 0: \n",
    "                results.append(np.nan)\n",
    "            else:\n",
    "                idx = arr.argmax()  \n",
    "                results.append(categories[idx])\n",
    "    \n",
    "        return results\n",
    "\n",
    "    def save(self, path=\"static_encoded.pkl\"):\n",
    "        joblib.dump(self.encoders, path)\n",
    "\n",
    "    def load(self, path=\"static_encoded.pkl\"):\n",
    "        self.encoders = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d3f00c7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_manager = StaticOneHotManager()\n",
    "static_manager.fit(static_df,static_df.columns)\n",
    "static_manager.save()\n",
    "static_one_hot = static_manager.transform(static_df,static_df.columns)\n",
    "static_one_hot.to_pickle(\"static_one_hot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "747ee5d4",
    "outputId": "728e5285-35ae-4c0d-92d4-6b1e69a0ccc0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6a23fa0",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loaded = pd.read_pickle(\"static_one_hot.pkl\")\n",
    "manager2 = StaticOneHotManager()\n",
    "manager2.load()\n",
    "decoded_race = manager2.inverse_transform(loaded[\"RACE\"], \"RACE\")\n",
    "decoded_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8a32272",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_df = pd.read_csv('temporal_categorical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ab8ee61",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TemporalOneHotManager:\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "\n",
    "    def fit(self, df, categorical_cols):\n",
    "        for col in categorical_cols:\n",
    "            flat_values = []\n",
    "            for seq in df[col]:\n",
    "                if pd.isna(seq):\n",
    "                    continue\n",
    "                if isinstance(seq, str):\n",
    "                    try:\n",
    "                        seq = ast.literal_eval(seq.replace('nan', 'None'))\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        seq = [seq]\n",
    "                if not isinstance(seq, list):\n",
    "                    seq = [seq]\n",
    "                for v in seq:\n",
    "                    if pd.notna(v):\n",
    "                        flat_values.append(str(v))\n",
    "\n",
    "            categories = pd.Series(flat_values).unique().tolist()\n",
    "            enc = OneHotEncoder(\n",
    "                sparse_output=False,\n",
    "                handle_unknown=\"ignore\",\n",
    "                categories=[categories]\n",
    "            )\n",
    "            enc.fit(np.array(categories).reshape(-1, 1))\n",
    "            self.encoders[col] = enc\n",
    "\n",
    "    def transform(self, df, categorical_cols, return_numpy=True):\n",
    "        out = pd.DataFrame()\n",
    "        if \"PATIENT\" in df.columns:\n",
    "            out[\"PATIENT\"] = df[\"PATIENT\"]\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            enc = self.encoders[col]\n",
    "            cats = enc.categories_[0].tolist()\n",
    "            n_cats = len(cats)\n",
    "\n",
    "            rows = []\n",
    "            for seq in df[col]:\n",
    "                if pd.isna(seq):\n",
    "                    seq = []\n",
    "                elif isinstance(seq, str):\n",
    "                    try:\n",
    "                        seq = ast.literal_eval(seq.replace('nan', 'None'))\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        seq = [seq]\n",
    "\n",
    "                if not isinstance(seq, list):\n",
    "                    seq = [seq]\n",
    "\n",
    "                encoded_seq = []\n",
    "                for v in seq:\n",
    "                    if pd.isna(v):\n",
    "                        if n_cats > 0:\n",
    "                            encoded_seq.append([0] * n_cats)\n",
    "                    else:\n",
    "                        if n_cats > 0:\n",
    "                            arr = enc.transform([[str(v)]]).flatten()\n",
    "                            encoded_seq.append(arr.astype(int).tolist())\n",
    "                rows.append(encoded_seq)\n",
    "            out[col] = rows\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def inverse_transform(self, series, col):\n",
    "        enc = self.encoders[col]\n",
    "        cats = enc.categories_[0].tolist()\n",
    "        results = []\n",
    "    \n",
    "        for row in series:\n",
    "            arr = np.array(row, dtype=float)\n",
    "            if arr.sum() == 0:\n",
    "                results.append(np.nan)\n",
    "            else:\n",
    "                results.append(cats[arr.argmax()])\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, path=\"temporal_encoded.pkl\"):\n",
    "        joblib.dump(self.encoders, path)\n",
    "\n",
    "    def load(self, path=\"temporal_encoded.pkl\"):\n",
    "        self.encoders = joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c69bd4a6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cols = temporal_df.columns[1:]\n",
    "temporal_manager = TemporalOneHotManager()\n",
    "temporal_manager.fit(temporal_df,cols)\n",
    "temporal_manager.save()\n",
    "temporal_one_hot = temporal_manager.transform(temporal_df,cols)\n",
    "temporal_one_hot.to_pickle(\"temporal_one_hot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba80f8f5",
    "outputId": "dbb5d2c8-c562-40f1-ae67-79e91ae702ad",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b803220",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def flatten_static_data(input_path: str, output_path: str):\n",
    "    df_original = pd.read_pickle(input_path)\n",
    "    all_flat_columns = []\n",
    "    for col in df_original.columns:\n",
    "        flat_cols = df_original[col].apply(pd.Series).add_prefix(f'{col}_')\n",
    "        all_flat_columns.append(flat_cols)\n",
    "    df_flat = pd.concat(all_flat_columns, axis=1)\n",
    "    numpy_array = df_flat.to_numpy(dtype=np.float32)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(numpy_array, f)\n",
    "\n",
    "    print(f\"Original shape: {df_original.shape}\")\n",
    "    print(f\"New flattened NumPy array shape: {numpy_array.shape}\")\n",
    "    print(f\"Saved flattened NumPy array to {output_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d75af99",
    "outputId": "942918cc-56ae-4d0c-cc57-9a9ca257a67e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "STATIC_INPUT_PATH = \"static_one_hot.pkl\"\n",
    "STATIC_OUTPUT_PATH = \"static_one_hot_flat.pkl\"\n",
    "flatten_static_data(STATIC_INPUT_PATH, STATIC_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dedbabf1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def flatten_temporal_data(input_path: str, output_path: str) -> np.ndarray:\n",
    "    df_original = pd.read_pickle(input_path)\n",
    "    all_timestamps_flat: List[list] = []\n",
    "    for index, patient_row in df_original.iterrows():\n",
    "        sequence_length = len(patient_row.iloc[0])\n",
    "        for t in range(sequence_length):\n",
    "            single_timestamp_parts = []\n",
    "            for feature in df_original.columns:\n",
    "                one_hot_vector = patient_row[feature][t]\n",
    "                single_timestamp_parts.extend(one_hot_vector)\n",
    "            all_timestamps_flat.append(single_timestamp_parts)\n",
    "    training_data = np.array(all_timestamps_flat, dtype=np.float32)\n",
    "\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(training_data, f)\n",
    "\n",
    "    print(f\"Successfully created flattened training data.\")\n",
    "    print(f\"  - Total patients processed: {len(df_original)}\")\n",
    "    print(f\"  - Final training data shape: {training_data.shape}\")\n",
    "    print(f\"  - Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e51683c3",
    "outputId": "eaa64a47-93a0-466f-ef52-568813ca2e78",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TEMPORAL_INPUT_PATH = \"temporal_one_hot.pkl\"\n",
    "TEMPORAL_OUTPUT_PATH = \"temporal_one_hot_flat.pkl\"\n",
    "flatten_temporal_data(TEMPORAL_INPUT_PATH, TEMPORAL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "086dc952",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OneHotDataset(Dataset):\n",
    "    def __init__(self, numpy_array):\n",
    "        self.data = torch.from_numpy(numpy_array)\n",
    "        print(f\"Created dataset with shape: {self.data.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return (self.data[idx],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1758880582870,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "d38d815d",
    "outputId": "6590d2b5-e828-4d6b-ac78-85cfec7190e3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "STATIC_FILE_PATH = \"static_one_hot_flat.pkl\"\n",
    "with open(STATIC_FILE_PATH, 'rb') as f:\n",
    "    full_dataset = pickle.load(f)\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    full_dataset,\n",
    "    test_size=0.1,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f\"\\nData split into:\")\n",
    "print(f\" - Training set shape: {train_data.shape}\")\n",
    "print(f\" - Validation set shape: {val_data.shape}\")\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "static_train_dataset = OneHotDataset(train_data)\n",
    "static_val_dataset = OneHotDataset(val_data)\n",
    "\n",
    "static_train_dataloader = DataLoader(dataset=static_train_dataset, batch_size=64, shuffle=True)\n",
    "static_val_dataloader = DataLoader(dataset=static_val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "STATIC_FILE_PATH = \"/kaggle/input/static-data/static_one_hot_flat.pkl\"\n",
    "with open(STATIC_FILE_PATH, 'rb') as f:\n",
    "    full_dataset = pickle.load(f)\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    full_dataset,\n",
    "    test_size=0.05,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f\"\\nData split into:\")\n",
    "print(f\" - Training set shape: {train_data.shape}\")\n",
    "print(f\" - Validation set shape: {val_data.shape}\")\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "static_train_dataset = OneHotDataset(train_data)\n",
    "static_val_dataset = OneHotDataset(val_data)\n",
    "\n",
    "static_train_dataloader = DataLoader(\n",
    "    static_train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=8,     \n",
    "    pin_memory=True    \n",
    ")\n",
    "\n",
    "static_val_dataloader = DataLoader(\n",
    "    static_val_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1758880591307,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "58619923",
    "outputId": "a2a98a84-2431-49b9-f45c-1de577a97c6b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_batch = next(iter(static_train_dataloader))\n",
    "print(f\"Shape of one static batch: {static_batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.get_device_name(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24829,
     "status": "ok",
     "timestamp": 1758900736437,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "e632761e",
    "outputId": "33c90321-b401-436e-e1e7-af6019e7443b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TEMPORAL_FILE_PATH = \"/kaggle/input/temporal-one-hot/temporal_one_hot_flat.pkl\"\n",
    "with open(TEMPORAL_FILE_PATH, 'rb') as f:\n",
    "    full_dataset = pickle.load(f)\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    full_dataset,\n",
    "    test_size=0.05,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(f\"\\nData split into:\")\n",
    "print(f\" - Training set shape: {train_data.shape}\")\n",
    "print(f\" - Validation set shape: {val_data.shape}\")\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "temporal_train_dataset = OneHotDataset(train_data)\n",
    "temporal_val_dataset = OneHotDataset(val_data)\n",
    "\n",
    "temporal_train_dataloader = DataLoader(\n",
    "    temporal_train_dataset,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    num_workers=8,     \n",
    "    pin_memory=True    \n",
    ")\n",
    "\n",
    "temporal_val_dataloader = DataLoader(\n",
    "    temporal_val_dataset,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1758900743276,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "8f5cd57c",
    "outputId": "7c44f87e-4751-46b4-97df-0c60575df103",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_batch = next(iter(temporal_train_dataloader))\n",
    "print(f\"Shape of one temporal batch: {temporal_batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CategoricalAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dims, lr=1e-3, optimizer_type=\"adam\", use_scheduler=False, filename=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dims = input_dims\n",
    "        self.filename = filename\n",
    "        self.total_input_dim = sum(self.input_dims)\n",
    "        self.num_features = len(self.input_dims)\n",
    "        hidden_dim = max(256, self.total_input_dim)\n",
    "        latent_dim = max(32, min(self.total_input_dim // 8, self.total_input_dim - 1))\n",
    "\n",
    "        # ------ Encoder -----------\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.total_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # -------- Decoders: one head per feature ----------\n",
    "        self.decoders = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                \n",
    "                nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(0.3),\n",
    "                \n",
    "                nn.Linear(hidden_dim, k)\n",
    "            )\n",
    "            for k in self.input_dims\n",
    "        ])\n",
    "        \n",
    "        #--------- Loss & Optimizer ---------\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        if optimizer_type == \"adam\":\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        elif optimizer_type.lower() == \"rmsprop\":\n",
    "            self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(\"optimizer_type must be Adam or RMSprop\")\n",
    "\n",
    "        self.scheduler = (optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min',\n",
    "                                                              factor=0.5, patience=3)\n",
    "                         if use_scheduler else None)\n",
    "\n",
    "    # ---------- Forward / Encode / Decode ----------\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits_list = [head(z) for head in self.decoders]\n",
    "        return logits_list\n",
    "\n",
    "    def encode(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z: torch.Tensor, mask=None, return_onehot=True):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits_list = [head(z) for head in self.decoders]\n",
    "            preds = [logits.argmax(dim=-1) for logits in logits_list]\n",
    "    \n",
    "            if not return_onehot:\n",
    "                return preds\n",
    "    \n",
    "            bsz = z.shape[0]\n",
    "            parts = []\n",
    "    \n",
    "            for i, (idxs, K) in enumerate(zip(preds, self.input_dims)):\n",
    "                onehot = torch.zeros(bsz, K, device=z.device)\n",
    "                onehot.scatter_(1, idxs.view(-1, 1), 1.0)\n",
    "                \n",
    "                if mask is not None:\n",
    "                    # mask[:, i] has shape (batch_size,)\n",
    "                    onehot = onehot * mask[:, i].unsqueeze(1)  # broadcast to (batch_size, K)\n",
    "                \n",
    "                parts.append(onehot)\n",
    "    \n",
    "            return preds, torch.cat(parts, dim=1)\n",
    "\n",
    "\n",
    "    def predict_prob(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits_list = self.forward(x)\n",
    "            probs_list = [F.softmax(logits, dim=-1) for logits in logits_list]\n",
    "        return probs_list\n",
    "\n",
    "    # ---------- Reconstruct with mask for missingness ----------\n",
    "    def reconstruct(self, x, return_onehot=False):\n",
    "        probs_list = self.predict_prob(x)\n",
    "        preds = []\n",
    "        bsz = x.shape[0]\n",
    "        parts = []\n",
    "\n",
    "        start = 0\n",
    "        for i, K in enumerate(self.input_dims):\n",
    "            end = start + K\n",
    "            segment = x[:, start:end]\n",
    "\n",
    "            # All-zero mask for missing features\n",
    "            mask_all_zero = (segment.sum(dim=1) == 0)\n",
    "            segment_logits = probs_list[i]\n",
    "            segment_pred = segment_logits.argmax(dim=-1)\n",
    "            preds.append(segment_pred)\n",
    "\n",
    "            if return_onehot:\n",
    "                onehot = torch.zeros(bsz, K, device=x.device)\n",
    "                idxs_to_scatter = (~mask_all_zero).nonzero(as_tuple=True)[0]\n",
    "                if len(idxs_to_scatter) > 0:\n",
    "                    onehot[idxs_to_scatter].scatter_(1, segment_pred[idxs_to_scatter].view(-1,1), 1.0)\n",
    "                parts.append(onehot)\n",
    "\n",
    "            start = end\n",
    "\n",
    "        if return_onehot:\n",
    "            return preds, torch.cat(parts, dim=1)\n",
    "        return preds\n",
    "\n",
    "    # ---------- Helper functions ----------\n",
    "    def _targets_from_onehot(self, x):\n",
    "        parts = torch.split(x, self.input_dims, dim=1)\n",
    "        return torch.stack([p.argmax(dim=1) for p in parts], dim=1).long()\n",
    "\n",
    "    def _compute_loss(self, logits_list, targets, mask=None):\n",
    "        loss = 0.0\n",
    "        for i, logits in enumerate(logits_list):\n",
    "            if mask is not None:\n",
    "                present_idx = (mask[:, i] == 1).nonzero(as_tuple=True)[0]\n",
    "                if len(present_idx) == 0:\n",
    "                    continue  # skip missing features\n",
    "                loss += self.criterion(logits[present_idx], targets[present_idx, i])\n",
    "            else:\n",
    "                loss += self.criterion(logits, targets[:, i])\n",
    "        return loss\n",
    "\n",
    "    # ---------- Training ----------\n",
    "    def fit(self, dataloader, epochs=10, val_dataloader=None, wrapper_model=None, mask_val=None):\n",
    "        forward_model = wrapper_model if wrapper_model is not None else self\n",
    "        best_val_loss = float('inf')\n",
    "        best_weights = None\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.train()\n",
    "            epoch_losses = []\n",
    "\n",
    "            for (x,) in tqdm(dataloader, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "                x = x.to(next(self.parameters()).device, non_blocking=True)\n",
    "                y = self._targets_from_onehot(x)\n",
    "                self.optimizer.zero_grad()\n",
    "                logits_list = forward_model(x)\n",
    "                loss = self._compute_loss(logits_list, y)\n",
    "                if wrapper_model is not None:\n",
    "                    loss = loss.mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "            train_loss = sum(epoch_losses) / max(1, len(epoch_losses))\n",
    "\n",
    "            val_loss = None\n",
    "            if val_dataloader is not None:\n",
    "                self.eval()\n",
    "                val_losses = []\n",
    "                with torch.no_grad():\n",
    "                    for i, (vx,) in enumerate(val_dataloader):\n",
    "                        vx = vx.to(next(self.parameters()).device, non_blocking=True)\n",
    "                        vy = self._targets_from_onehot(vx)\n",
    "                        vlogits_list = forward_model(vx)\n",
    "                        if mask_val is not None:\n",
    "                            vloss = self._compute_loss(vlogits_list, vy, mask=mask_val[i*vx.size(0):(i+1)*vx.size(0)])\n",
    "                        else:\n",
    "                            vloss = self._compute_loss(vlogits_list, vy)\n",
    "                        val_losses.append(vloss.item())\n",
    "                val_loss = sum(val_losses) / max(1, len(val_losses))\n",
    "\n",
    "                if self.scheduler is not None:\n",
    "                    self.scheduler.step(val_loss)\n",
    "\n",
    "                # Save best weights\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_weights = self.state_dict()\n",
    "\n",
    "            print(f\"Epoch {epoch:03d} | Train {train_loss:.7f} | \"\n",
    "                  f\"Val {val_loss:.7f}\" if val_loss is not None else f\"Epoch {epoch:03d} | Train {train_loss:.7f}\")\n",
    "\n",
    "        # Save best weights\n",
    "        if best_weights is not None:\n",
    "            torch.save(best_weights, self.filename)\n",
    "            print(f\"Best model saved with val_loss={best_val_loss:.7f} as {self.filename}\")\n",
    "        else:\n",
    "            self.save_model()\n",
    "\n",
    "    # ---------- Save / Load ----------\n",
    "    def save_model(self):\n",
    "        torch.save(self.state_dict(), self.filename)\n",
    "        print(f\"Model saved as {self.filename}\")\n",
    "\n",
    "    def load_model(self, map_location=None):\n",
    "        state = torch.load(self.filename, map_location=map_location)\n",
    "        self.load_state_dict(state)\n",
    "        self.eval()\n",
    "        print(f\"Model loaded from {self.filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqLeVOTDdTnW"
   },
   "source": [
    "Training Static One Hot into Latent Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2084,
     "status": "ok",
     "timestamp": 1758880602280,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "1f76d4ab",
    "outputId": "3c841f17-4121-4a12-8235-4af76eec2bc3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_one_hot = pd.read_pickle('/kaggle/input/static-data/static_one_hot.pkl')\n",
    "static_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1758880605856,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "tZmt7FCuXruA",
    "outputId": "301a68c0-3096-41a3-f662-a85d65dcc920",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dims = [len(static_one_hot.iloc[0][col]) for col in static_one_hot.columns]\n",
    "input_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "228cbb93",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_instance = CategoricalAutoEncoder(input_dims,use_scheduler=True,filename=\"static_categorical_encoder_decoder.pt\")\n",
    "model_wrapper = nn.DataParallel(model_instance)\n",
    "model_wrapper = model_wrapper.to(device)\n",
    "model_wrapper.module.fit(static_train_dataloader, epochs=30, val_dataloader=static_val_dataloader,wrapper_model=model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_instance = CategoricalAutoEncoder(input_dims, filename=\"static_categorical_encoder_decoder.pt\")\n",
    "model_instance = model_instance.to(device)\n",
    "model_instance.load_model(map_location=device)\n",
    "x_sample = next(iter(static_val_dataloader))[0].to(device)\n",
    "mask_list = []\n",
    "start = 0\n",
    "for dim in input_dims:\n",
    "    end = start + dim\n",
    "    feature_segment = x_sample[:, start:end]\n",
    "    feature_mask = (feature_segment.sum(dim=1) > 0).float()\n",
    "    mask_list.append(feature_mask)\n",
    "    start = end\n",
    "\n",
    "mask = torch.stack(mask_list, dim=1).to(device)  \n",
    "\n",
    "z = model_instance.encode(x_sample)\n",
    "preds, recon = model_instance.decode(z, mask=mask, return_onehot=True)\n",
    "\n",
    "print(\"Original (first row):\\n\", x_sample[64])\n",
    "print(\"Reconstructed (first row):\\n\", recon[64])\n",
    "num_features = len(input_dims)\n",
    "start = 0\n",
    "accuracies = []\n",
    "\n",
    "for i, dim in enumerate(input_dims):\n",
    "    end = start + dim\n",
    "    original_segment = x_sample[:, start:end]\n",
    "    recon_segment = recon[:, start:end]\n",
    "    present_mask = mask[:, i].unsqueeze(1) \n",
    "    if present_mask.sum() > 0:\n",
    "        acc = ((original_segment * present_mask) == (recon_segment * present_mask)).float().mean().item()\n",
    "    else:\n",
    "        acc = float('nan')  \n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    start = end\n",
    "for i, acc in enumerate(accuracies):\n",
    "    if not acc != acc:  # check for nan\n",
    "        print(f\"Feature {i} (length {input_dims[i]}): Bitwise accuracy {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Feature {i} (length {input_dims[i]}): No present values in batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1758881232224,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "bLwqyZOXY6Rp",
    "outputId": "99ae76e2-987e-4b6b-88fe-b4d06844d04f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = CategoricalAutoEncoder(input_dims,filename=\"static_categorical_encoder_decoder.pt\")\n",
    "new_model.load_model()\n",
    "\n",
    "sample_batch, = next(iter(static_train_dataloader))\n",
    "encodings = new_model.encode(sample_batch)\n",
    "print(encodings.shape)  # (batch_size, latent_dim)\n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = CategoricalAutoEncoder(input_dims,filename=\"temporal_categorical_encoder_decoder.pt\")\n",
    "new_model.load_model()\n",
    "\n",
    "sample_batch, = next(iter(static_train_dataloader))\n",
    "encodings = new_model.encode(sample_batch)\n",
    "print(encodings.shape)  # (batch_size, latent_dim)\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhc0z9g9uvln"
   },
   "source": [
    "Training Temporal One Hot into Latent Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PxGESkCu3qw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_one_hot = pd.read_pickle('temporal_one_hot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1758900105360,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "FLF0i4yRu7SI",
    "outputId": "0854b817-3ec0-41e2-e0e3-2a9e6de505da",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dims = [len(temporal_one_hot.iloc[0][col][0]) for col in temporal_one_hot.columns]\n",
    "input_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oowx19Vlp6JQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dims = [76, 68, 126, 28, 99, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etrhU9sDu9rW",
    "outputId": "7705b7b9-225a-49c6-8a68-b63eab5e6ecb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_instance = CategoricalAutoEncoder(input_dims,use_scheduler=True,filename=\"temporal_categorical_encoder_decoder.pt\")\n",
    "model_wrapper = nn.DataParallel(model_instance)\n",
    "model_wrapper = model_wrapper.to(device)\n",
    "model_wrapper.module.fit(temporal_train_dataloader, epochs=50, val_dataloader=temporal_val_dataloader,wrapper_model=model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_instance = CategoricalAutoEncoder(input_dims, filename=\"temporal_categorical_encoder_decoder.pt\")\n",
    "model_instance = model_instance.to(device)\n",
    "model_instance.load_model(map_location=device)\n",
    "x_sample = next(iter(temporal_val_dataloader))[0].to(device)\n",
    "preds, recon = model_instance.reconstruct(x_sample,return_onehot=True)\n",
    "print(\"Original (first 5 rows):\\n\", x_sample[:1])\n",
    "print(\"Reconstructed (first 5 rows):\\n\", recon[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_instance = CategoricalAutoEncoder(input_dims, filename=\"temporal_categorical_encoder_decoder.pt\")\n",
    "model_instance = model_instance.to(device)\n",
    "model_instance.load_model(map_location=device)\n",
    "x_sample = next(iter(temporal_train_dataloader))[0].to(device)\n",
    "mask_list = []\n",
    "start = 0\n",
    "for dim in input_dims:\n",
    "    end = start + dim\n",
    "    feature_segment = x_sample[:, start:end]\n",
    "    feature_mask = (feature_segment.sum(dim=1) > 0).float()\n",
    "    mask_list.append(feature_mask)\n",
    "    start = end\n",
    "\n",
    "mask = torch.stack(mask_list, dim=1).to(device)  \n",
    "\n",
    "z = model_instance.encode(x_sample)\n",
    "preds, recon = model_instance.decode(z, mask=mask, return_onehot=True)\n",
    "\n",
    "print(\"Original (first row):\\n\", x_sample[30])\n",
    "print(\"Reconstructed (first row):\\n\", recon[30])\n",
    "num_features = len(input_dims)\n",
    "start = 0\n",
    "accuracies = []\n",
    "\n",
    "for i, dim in enumerate(input_dims):\n",
    "    end = start + dim\n",
    "    original_segment = x_sample[:, start:end]\n",
    "    recon_segment = recon[:, start:end]\n",
    "    present_mask = mask[:, i].unsqueeze(1) \n",
    "    if present_mask.sum() > 0:\n",
    "        acc = ((original_segment * present_mask) == (recon_segment * present_mask)).float().mean().item()\n",
    "    else:\n",
    "        acc = float('nan')  \n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    start = end\n",
    "for i, acc in enumerate(accuracies):\n",
    "    if not acc != acc:  # check for nan\n",
    "        print(f\"Feature {i} (length {input_dims[i]}): Bitwise accuracy {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Feature {i} (length {input_dims[i]}): No present values in batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class StochasticNormalizer:\n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "\n",
    "    def stochastic_normalize(self, X: torch.Tensor, key=None):\n",
    "        X = X.float()\n",
    "        unique_vals, counts = torch.unique(X, return_counts=True)\n",
    "        N = X.numel()\n",
    "        X_hat = torch.empty_like(X, dtype=torch.float32, device=X.device)\n",
    "        lower_bound = 0.0\n",
    "        params = {}\n",
    "\n",
    "        for val, count in zip(unique_vals, counts):\n",
    "            ratio = count.item() / N\n",
    "            upper_bound = lower_bound + ratio\n",
    "            mask = X == val\n",
    "            X_hat[mask] = torch.rand(mask.sum(), device=X.device) * (upper_bound - lower_bound) + lower_bound\n",
    "            params[val.item()] = [lower_bound, upper_bound]\n",
    "            lower_bound = upper_bound\n",
    "\n",
    "        if key is not None:\n",
    "            self.params[key] = params\n",
    "        return X_hat\n",
    "\n",
    "    def stochastic_renormalize(self, X_hat: torch.Tensor, key=None):\n",
    "        X_hat = X_hat.float()\n",
    "        X = torch.zeros_like(X_hat, dtype=torch.float32, device=X_hat.device)\n",
    "        if key is not None:\n",
    "            params = self.params[key]\n",
    "\n",
    "        for val, (low, high) in params.items():\n",
    "            mask = (X_hat >= low) & (X_hat < high)\n",
    "            X[mask] = val\n",
    "\n",
    "        # Handle edge case where X_hat == 1.0\n",
    "        mask = X_hat == 1.0\n",
    "        for val, (low, high) in params.items():\n",
    "            if abs(high - 1.0) < 1e-8:\n",
    "                X[mask] = val\n",
    "        return X\n",
    "\n",
    "    def normalize_sample(self, X: torch.Tensor, key):\n",
    "        if key not in self.params:\n",
    "            raise ValueError(f\"No parameters found for key '{key}'. Load or train first.\")\n",
    "\n",
    "        params = self.params[key]\n",
    "        X_hat = torch.zeros_like(X, dtype=torch.float32, device=X.device)\n",
    "        for val, (low, high) in params.items():\n",
    "            mask = X == val\n",
    "            if mask.any():\n",
    "                X_hat[mask] = torch.rand(mask.sum(), device=X.device) * (high - low) + low\n",
    "        return X_hat\n",
    "\n",
    "    def save_params(self, filepath):\n",
    "        torch.save(self.params, filepath)\n",
    "\n",
    "    def load_params(self, filepath):\n",
    "        self.params = torch.load(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1758884348044,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "WkzJL7SCgI5I",
    "outputId": "75808591-124f-4219-d0a0-083bc43b1ceb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_numerical = pd.read_csv('/kaggle/input/numerical-data/static_numerical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1758884350019,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "BBAUQAKUiKbH",
    "outputId": "1166dfb3-14e3-4bb2-e9c9-dcfd49ad0821",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_age = torch.tensor(static_numerical[\"AGE\"].values, dtype=torch.float32)\n",
    "normalizer  = StochasticNormalizer()\n",
    "X_hat_age = normalizer.stochastic_normalize(X_age,key = \"AGE\")\n",
    "normalizer.save_params(\"static_params.pt\")\n",
    "static_numerical[\"AGE_normalized\"] = X_hat_age.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15067,
     "status": "ok",
     "timestamp": 1758882975867,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "L_j-o1msgWJ9",
    "outputId": "c8cefee6-9af4-4e1a-aa37-573aa409df27",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_numerical = pd.read_csv('/kaggle/input/numerical-data/temporal_numerical.csv')\n",
    "for col in temporal_numerical.columns:\n",
    "    temporal_numerical[col] = temporal_numerical[col].apply(lambda x: json.loads(x.replace(\"nan\", \"null\")) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 129999,
     "status": "ok",
     "timestamp": 1758884008428,
     "user": {
      "displayName": "Arush Jaiswal",
      "userId": "18280738540485237776"
     },
     "user_tz": -330
    },
    "id": "ijvKVgkkmHqj",
    "outputId": "1c5a18e8-ac43-4c1f-8f0b-c93496ca2a37",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "normalizer = StochasticNormalizer()\n",
    "for col_idx, col in enumerate(temporal_numerical.columns):\n",
    "    all_values = []\n",
    "    lengths_per_cell = []\n",
    "\n",
    "    for row in temporal_numerical[col]:\n",
    "        if isinstance(row, list):\n",
    "            clean_vals = [v for v in row if v is not None and not pd.isna(v)]\n",
    "            \n",
    "            if col_idx == 0 and len(clean_vals) > 1:  \n",
    "                deltas = [clean_vals[0]] + [clean_vals[i] - clean_vals[i-1] for i in range(1, len(clean_vals))]\n",
    "                all_values.extend(deltas)\n",
    "            else:\n",
    "                all_values.extend(clean_vals)\n",
    "            \n",
    "            lengths_per_cell.append(len(row))\n",
    "        else:\n",
    "            lengths_per_cell.append(0)\n",
    "\n",
    "    X = torch.tensor(all_values, dtype=torch.float32)\n",
    "    X_hat = normalizer.stochastic_normalize(X, key=col)\n",
    "\n",
    "    normalized_col = []\n",
    "    counter = 0\n",
    "    for row in temporal_numerical[col]:\n",
    "        if isinstance(row, list) and len(row) > 0:\n",
    "            n_valid = len([v for v in row if v is not None and not pd.isna(v)])\n",
    "            norm_cell = X_hat[counter:counter+n_valid].tolist()\n",
    "            counter += n_valid\n",
    "\n",
    "            norm_cell_with_nan = []\n",
    "            idx_norm = 0\n",
    "            for v in row:\n",
    "                if v is None or pd.isna(v):\n",
    "                    norm_cell_with_nan.append(float('nan'))\n",
    "                else:\n",
    "                    norm_cell_with_nan.append(norm_cell[idx_norm])\n",
    "                    idx_norm += 1\n",
    "            normalized_col.append(norm_cell_with_nan)\n",
    "        else:\n",
    "            normalized_col.append([])\n",
    "\n",
    "    temporal_numerical[col] = normalized_col\n",
    "\n",
    "normalizer.save_params(\"temporal_params.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_static_num(patient_row, feature_cols):\n",
    "    values = []\n",
    "    masks = []\n",
    "\n",
    "    for col in feature_cols:\n",
    "        val = patient_row[col]\n",
    "        if pd.isna(val):\n",
    "            values.append(0.0)\n",
    "            masks.append(0.0)\n",
    "        else:\n",
    "            values.append(val)\n",
    "            masks.append(1.0)\n",
    "\n",
    "    sn = torch.tensor(values, dtype=torch.float32)     \n",
    "    sn_mask = torch.tensor(masks, dtype=torch.float32) \n",
    "\n",
    "    return sn, sn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_temporal_num(patient_row, feature_cols, date_col=\"DATE\"):\n",
    "    seqs = []\n",
    "    masks = []\n",
    "\n",
    "    for col in feature_cols:\n",
    "        values = patient_row[col]\n",
    "        if isinstance(values, str):\n",
    "            values = ast.literal_eval(values)\n",
    "\n",
    "        arr = np.array(values, dtype=np.float32)\n",
    "        mask = ~np.isnan(arr)\n",
    "        arr[np.isnan(arr)] = 0\n",
    "\n",
    "        seqs.append(arr)\n",
    "        masks.append(mask.astype(np.float32))\n",
    "    seqs = np.stack(seqs, axis=-1)\n",
    "    masks = np.stack(masks, axis=-1)\n",
    "    timestamps = patient_row[date_col]\n",
    "    if isinstance(timestamps, str):\n",
    "        timestamps = ast.literal_eval(timestamps)\n",
    "    timestamps = np.array(timestamps, dtype=np.float32)\n",
    "    tn = torch.tensor(seqs, dtype=torch.float32)          # [seq_len, num_features]\n",
    "    tn_mask = torch.tensor(masks, dtype=torch.float32)    # [seq_len, num_features]\n",
    "    un = torch.tensor(timestamps, dtype=torch.float32)       # [seq_len]\n",
    "\n",
    "    return tn, tn_mask, un, tn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_num_tensor = []\n",
    "static_num_mask_tensor = []\n",
    "\n",
    "for idx, row in static_numerical.iterrows():\n",
    "    sn, sn_mask = process_static_num(row, feature_cols=['AGE_normalized'])\n",
    "    static_num_tensor.append(sn)\n",
    "    static_num_mask_tensor.append(sn_mask)\n",
    "\n",
    "static_num_tensor = torch.stack(static_num_tensor, dim=0)       \n",
    "static_num_mask_tensor = torch.stack(static_num_mask_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tn_list = []\n",
    "tn_mask_list = []\n",
    "un_list = []\n",
    "seq_len_num = []\n",
    "feature_cols = temporal_numerical.columns[1:]\n",
    "for idx, row in temporal_numerical.iterrows():\n",
    "    tn, tn_mask, un, seq_len = process_temporal_num(row, feature_cols, date_col=\"DATE\")\n",
    "    tn_list.append(tn)\n",
    "    tn_mask_list.append(tn_mask)\n",
    "    un_list.append(un)\n",
    "    seq_len_num.append(seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_categorical = pd.read_pickle('/kaggle/input/static-data/static_one_hot_flat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_categorical = pd.read_pickle('/kaggle/input/temporal-one-hot/temporal_one_hot_flat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/temporal-csv/temporal_categorical.csv')\n",
    "temporal_times = df[df.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "parsed_rows = [ast.literal_eval(row) if isinstance(row, str) else row for row in temporal_times]\n",
    "\n",
    "delta_rows = []\n",
    "for row in parsed_rows:\n",
    "    row = torch.tensor(row, dtype=torch.float32)\n",
    "    delta = torch.empty_like(row)\n",
    "    delta[0] = row[0] \n",
    "    if len(row) > 1:\n",
    "        delta[1:] = row[1:] - row[:-1]  \n",
    "    delta_rows.append(delta)\n",
    "\n",
    "all_deltas = torch.cat(delta_rows)\n",
    "\n",
    "normalizer = StochasticNormalizer()\n",
    "X_hat = normalizer.stochastic_normalize(all_deltas, key=\"DATE\")\n",
    "\n",
    "normalized_times = []\n",
    "counter = 0\n",
    "for delta in delta_rows:\n",
    "    length = len(delta)\n",
    "    norm_row = X_hat[counter:counter+length].tolist()\n",
    "    normalized_times.append(norm_row)\n",
    "    counter += length\n",
    "\n",
    "normalizer.save_params(\"categorical_times_params.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "uc_list = []\n",
    "for row in normalized_times:\n",
    "    if isinstance(row, str):\n",
    "        row = ast.literal_eval(row)\n",
    "    tensor_row = torch.tensor(row, dtype=torch.float32)\n",
    "    uc_list.append(tensor_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_static_cat(one_hot_row, model, input_dims, device=\"cpu\"):\n",
    "    if isinstance(one_hot_row, np.ndarray):\n",
    "        one_hot_row = torch.tensor(one_hot_row, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        one_hot_row = one_hot_row.to(device)\n",
    "    masks = []\n",
    "    start = 0\n",
    "    for dim in input_dims:\n",
    "        segment = one_hot_row[start:start+dim]\n",
    "        masks.append(0.0 if torch.all(segment == 0) else 1.0)\n",
    "        start += dim\n",
    "    sc_mask = torch.tensor(masks, dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sc = model.encode(one_hot_row.unsqueeze(0))  \n",
    "    sc = sc.squeeze(0)\n",
    "\n",
    "    return sc, sc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seq_lens = []\n",
    "for timestamps in temporal_times:\n",
    "    if isinstance(timestamps, str):\n",
    "        timestamps = ast.literal_eval(timestamps)\n",
    "    seq_lens.append(len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_temporal_one_hot(flat_array, seq_lens):\n",
    "    sequences = []\n",
    "    start = 0\n",
    "    for l in seq_lens:\n",
    "        seq = flat_array[start:start+l]\n",
    "        sequences.append(seq)\n",
    "        start += l\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_temporal_cat(flat_seq_list, input_dims, model, device=\"cuda\"):\n",
    "    tc_list = []\n",
    "    tc_mask_list = []\n",
    "    seq_len_list = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for seq in tqdm(flat_seq_list):\n",
    "        seq_tensor = torch.tensor(seq, dtype=torch.float32, device=device)\n",
    "        seq_len_list.append(seq_tensor.shape[0])\n",
    "\n",
    "        masks = []\n",
    "        start = 0\n",
    "        for dim in input_dims:\n",
    "            segment = seq_tensor[:, start:start+dim]\n",
    "            mask_segment = (segment.abs().sum(dim=1) != 0).float().unsqueeze(1)\n",
    "            masks.append(mask_segment)\n",
    "            start += dim\n",
    "        masks = torch.cat(masks, dim=1)\n",
    "        tc_mask_list.append(masks)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            latent_seq = model.encode(seq_tensor)\n",
    "        tc_list.append(latent_seq)\n",
    "\n",
    "    return tc_list, tc_mask_list, seq_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_one_hot = pd.read_pickle('/kaggle/input/static-data/static_one_hot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "static_cat_list = []\n",
    "static_cat_mask_list = []\n",
    "static_input_dims = [len(static_one_hot.iloc[0][col]) for col in static_one_hot.columns]\n",
    "static_cat_model = CategoricalAutoEncoder(static_input_dims, filename='/kaggle/input/weights/static_categorical_encoder_decoder.pt')\n",
    "static_cat_model.load_model()\n",
    "static_cat_model.to(device)\n",
    "static_cat_model.eval()\n",
    "\n",
    "for vec in tqdm(static_categorical):\n",
    "    sc, sc_mask = process_static_cat(vec, static_cat_model, input_dims=static_input_dims, device=device)\n",
    "    static_cat_list.append(sc)\n",
    "    static_cat_mask_list.append(sc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temporal_input_dims = [76, 68, 126, 28, 99, 80]\n",
    "flat_array = temporal_categorical\n",
    "flat_seq_list = split_temporal_one_hot(flat_array, seq_lens)\n",
    "temporal_cat_model = CategoricalAutoEncoder(temporal_input_dims, filename=\"/kaggle/input/weights/temporal_categorical_encoder_decoder.pt\")\n",
    "temporal_cat_model.load_model()\n",
    "temporal_cat_model.to(device)\n",
    "temporal_cat_model.eval()\n",
    "tc_list, tc_mask_list, seq_len_cat = process_temporal_cat(flat_seq_list, temporal_input_dims, temporal_cat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderDataset(Dataset):\n",
    "    def __init__(self, static_num_tensor, static_num_mask_tensor,\n",
    "                 static_cat_list, static_cat_mask_list,\n",
    "                 tn_list, tn_mask_list, un_list,\n",
    "                 tc_list, tc_mask_list, uc_list):\n",
    "        self.static_num_tensor = static_num_tensor.cpu()\n",
    "        self.static_num_mask_tensor = static_num_mask_tensor.cpu()\n",
    "        self.static_cat_list = [t.cpu() for t in static_cat_list]\n",
    "        self.static_cat_mask_list = [t.cpu() for t in static_cat_mask_list]\n",
    "        self.tn_list = [t.cpu() for t in tn_list]\n",
    "        self.tn_mask_list = [t.cpu() for t in tn_mask_list]\n",
    "        self.un_list = [torch.as_tensor(u, dtype=torch.float32, device=\"cpu\") for u in un_list]\n",
    "        self.tc_list = [t.cpu() for t in tc_list]\n",
    "        self.tc_mask_list = [t.cpu() for t in tc_mask_list]\n",
    "        self.uc_list = [torch.as_tensor(u, dtype=torch.float32, device=\"cpu\") for u in uc_list]\n",
    "\n",
    "        self.num_patients = len(self.static_num_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_patients\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sn = self.static_num_tensor[idx]\n",
    "        sn_mask = self.static_num_mask_tensor[idx]\n",
    "        sc = self.static_cat_list[idx]\n",
    "        sc_mask = self.static_cat_mask_list[idx]\n",
    "        tn = self.tn_list[idx]\n",
    "        tn_mask = self.tn_mask_list[idx]\n",
    "        un = self.un_list[idx]\n",
    "        tc = self.tc_list[idx]\n",
    "        tc_mask = self.tc_mask_list[idx]\n",
    "        uc = self.uc_list[idx]\n",
    "\n",
    "        seq_len_num = tn.size(0)\n",
    "        seq_len_cat = tc.size(0)\n",
    "\n",
    "        return (\n",
    "            sn, sc, tn, tc, un, uc,\n",
    "            sn_mask, sc_mask, tn_mask, tc_mask,\n",
    "            seq_len_num, seq_len_cat\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    (sn_list, sc_list, \n",
    "     tn_list, tc_list, \n",
    "     un_list, uc_list, \n",
    "     sn_mask_list, sc_mask_list, \n",
    "     tn_mask_list, tc_mask_list, \n",
    "     seq_len_num_list, seq_len_cat_list) = zip(*batch)\n",
    "\n",
    "    sn = torch.stack(sn_list, dim=0)\n",
    "    sc = torch.stack(sc_list, dim=0)\n",
    "    sn_mask = torch.stack(sn_mask_list, dim=0)\n",
    "    sc_mask = torch.stack(sc_mask_list, dim=0)\n",
    "\n",
    "    tn = pad_sequence(tn_list, batch_first=True, padding_value=0.0)\n",
    "    tn_mask = pad_sequence(tn_mask_list, batch_first=True, padding_value=0.0)\n",
    "    un = pad_sequence(un_list, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    tc = pad_sequence(tc_list, batch_first=True, padding_value=0.0)\n",
    "    tc_mask = pad_sequence(tc_mask_list, batch_first=True, padding_value=0.0)\n",
    "    uc = pad_sequence(uc_list, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    seq_len_num = torch.tensor(seq_len_num_list, dtype=torch.long)\n",
    "    seq_len_cat = torch.tensor(seq_len_cat_list, dtype=torch.long)\n",
    "\n",
    "    return sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, seq_len_num, seq_len_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_MAX_SEQ_NUM = max(seq_len_num)\n",
    "GLOBAL_MAX_SEQ_CAT = max(seq_len_cat)\n",
    "print(GLOBAL_MAX_SEQ_NUM)\n",
    "print(GLOBAL_MAX_SEQ_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = EncoderDecoderDataset(static_num_tensor, static_num_mask_tensor,\n",
    "                                static_cat_list, static_cat_mask_list,\n",
    "                                tn_list, tn_mask_list, un_list,\n",
    "                                tc_list, tc_mask_list, uc_list)\n",
    "\n",
    "num_patients = len(dataset)\n",
    "val_ratio = 0.05\n",
    "val_size = int(num_patients * val_ratio)\n",
    "train_size = num_patients - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"\\nData split into:\")\n",
    "print(f\" - Training set: {train_size} patients\")\n",
    "print(f\" - Validation set: {val_size} patients\")\n",
    "print(\"\\n--- Creating DataLoaders ---\")\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,          \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "(sn, sc, tn, tc, un, uc, \n",
    " sn_mask, sc_mask, tn_mask, tc_mask, \n",
    " seq_len_num, seq_len_cat) = first_batch\n",
    "\n",
    "sample = (\n",
    "    sn[0], sc[0], tn[0], tc[0], un[0], uc[0],\n",
    "    sn_mask[0], sc_mask[0], tn_mask[0], tc_mask[0],\n",
    "    seq_len_num[0], seq_len_cat[0] \n",
    ")\n",
    "\n",
    "names = [\"sn\", \"sc\", \"tn\", \"tc\", \"un\", \"uc\",\n",
    "         \"sn_mask\", \"sc_mask\", \"tn_mask\", \"tc_mask\",\n",
    "         \"seq_len_num\", \"seq_len_cat\"]\n",
    "\n",
    "for name, value in zip(names, sample):\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        if value.dim() == 0:\n",
    "            print(f\"{name}: {value.item()}\")\n",
    "        else:\n",
    "            print(f\"{name}: {tuple(value.shape)}\")\n",
    "    else:\n",
    "        print(f\"{name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b24f92b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims=(512,256,256), out_dim=16, dropout=0.1,\n",
    "                 use_batch_norm=True, activation='lrelu', final_activation=None):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        activation_fn = {\n",
    "            'lrelu': nn.LeakyReLU(0.01),\n",
    "            'relu': nn.ReLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'swish': nn.SiLU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'sigmoid': nn.Sigmoid()\n",
    "        }[activation]\n",
    "\n",
    "        d = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(d,h))\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(activation_fn)\n",
    "            if dropout > 0.0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            d = h\n",
    "\n",
    "        layers.append(nn.Linear(d, out_dim))\n",
    "        if final_activation is not None:\n",
    "            layers.append(final_activation)   \n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "326ba9dd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self,in_dim,hidden_dim=256,out_dim=128,depth=2,use_post_mlp=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = in_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = depth,\n",
    "            batch_first = True,\n",
    "            dropout = 0.1\n",
    "        )\n",
    "\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        if use_post_mlp:\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_dim,hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Linear(hidden_dim,out_dim)\n",
    "            )\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim,out_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x: (batch, seq_len, in_dim)\n",
    "        out, _ = self.gru(x)\n",
    "        attn_scores = self.attn(out).squeeze(-1) # (batch,seq_len)\n",
    "        attn_weights = torch.softmax(attn_scores,dim=1)\n",
    "        context = torch.sum(out * attn_weights.unsqueeze(-1),dim=1) # (batch, hidden_dim)\n",
    "        return self.fc(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "494c8eba",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64], output_dim=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dims\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "            layers.append(nn.BatchNorm1d(dims[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.Linear(dims[-1], output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TemporalDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim = 512, depth = 2,\n",
    "                 num_features=None, embed_dim=None, is_categorical=False):\n",
    "        super().__init__()\n",
    "        self.is_categorical = is_categorical\n",
    "        self.fc_init_h = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, depth * hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=latent_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=depth,\n",
    "            batch_first=True,\n",
    "            dropout=0.1 if depth > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.head_value = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, embed_dim if is_categorical else num_features),\n",
    "            nn.Tanh() if is_categorical else nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.head_time = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim // 8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.head_mask = nn.Sequential(\n",
    "            nn.Linear(hidden_dim  , num_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, e, max_seq_len, mask_threshold = 0.5):\n",
    "        batch_size = e.size(0)\n",
    "        device = e.device\n",
    "        h_0_flat = self.fc_init_h(e)\n",
    "        h_0 = h_0_flat.view(self.gru.num_layers, batch_size, self.gru.hidden_size)\n",
    "\n",
    "        tn_hat_list, u_hat_list, mask_hat_list = [], [], []\n",
    "        h_t = h_0\n",
    "\n",
    "        seq_lengths = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
    "        active_sequences = torch.ones(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        for _ in range(max_seq_len):\n",
    "            if not active_sequences.any():\n",
    "                break\n",
    "\n",
    "            gru_input = e.unsqueeze(1)\n",
    "            gru_out, h_t_new = self.gru(gru_input, h_t)\n",
    "\n",
    "            h_t = torch.where(active_sequences.view(1, -1, 1), h_t_new, h_t) \n",
    "\n",
    "            tn_hat_step = self.head_value(gru_out.squeeze(1))\n",
    "            u_hat_step = self.head_time(gru_out.squeeze(1)) \n",
    "            mask_hat_step = self.head_mask(gru_out.squeeze(1))  \n",
    "\n",
    "            tn_hat_list.append(tn_hat_step)\n",
    "            u_hat_list.append(u_hat_step)\n",
    "            mask_hat_list.append(mask_hat_step)\n",
    "\n",
    "            seq_lengths += active_sequences.long()\n",
    "\n",
    "            stop_condition = (torch.sigmoid(mask_hat_step) < mask_threshold).all(dim=-1)\n",
    "            active_sequences = active_sequences & ~stop_condition\n",
    "\n",
    "        tn_hat = torch.stack(tn_hat_list, dim=1)\n",
    "        u_hat = torch.stack(u_hat_list, dim=1)\n",
    "        mask_hat = torch.stack(mask_hat_list, dim=1)\n",
    "\n",
    "        return tn_hat, u_hat, mask_hat, seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dae6d3d5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,sn_dim,sce_latent_dim,tn_dim,tce_latent_dim,sc_dim,tc_dim,latent_dim=512):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        static_input_dim = sn_dim + sce_latent_dim\n",
    "        self.static_encoder = MLP(static_input_dim, out_dim=128)\n",
    "        self.temporal_num_encoder = TemporalEncoder(tn_dim + 1, out_dim=256)\n",
    "        self.temporal_cat_encoder = TemporalEncoder(tce_latent_dim + 1, out_dim=256)\n",
    "        self.static_mask = MLP(in_dim = sn_dim + sc_dim,hidden_dims=(32,16,8),out_dim=4)\n",
    "        self.temporal_num_mask_encoder = TemporalEncoder(tn_dim,hidden_dim=128,out_dim=64)\n",
    "        self.temporal_cat_mask_encoder = TemporalEncoder(tc_dim,hidden_dim=128,out_dim=64)\n",
    "        fusion_dim = 128 + 256 + 256 + 4 + 64 + 64\n",
    "        self.fusion = FusionMLP(fusion_dim, hidden_dims=[2048, 1024], output_dim=latent_dim)\n",
    "        self.static_decoder_num = MLP(latent_dim, out_dim=sn_dim,final_activation=nn.Sigmoid())\n",
    "        self.static_decoder_cat = MLP(latent_dim,out_dim=sce_latent_dim,final_activation=nn.Tanh())\n",
    "        self.static_decoder_mask = MLP(latent_dim, out_dim=sn_dim + sc_dim)\n",
    "        self.temporal_decoder_num = TemporalDecoder(latent_dim, num_features=tn_dim, is_categorical=False)\n",
    "        self.temporal_decoder_cat = TemporalDecoder(latent_dim, num_features=tc_dim, embed_dim=tce_latent_dim,is_categorical=True)\n",
    "\n",
    "    def encode(self,sn,sc,tn,tc,un,uc,sn_mask,sc_mask,tn_mask,tc_mask):\n",
    "        static_in = torch.cat([sn,sc],dim=-1)\n",
    "        static_e = self.static_encoder(static_in)\n",
    "        un = un.unsqueeze(-1)\n",
    "        temporal_num_in = torch.cat([tn,un],dim=-1)\n",
    "        temporal_num_e = self.temporal_num_encoder(temporal_num_in)\n",
    "        uc = uc.unsqueeze(-1)\n",
    "        temporal_cat_in = torch.cat([tc,uc],dim=-1)\n",
    "        temporal_cat_e = self.temporal_cat_encoder(temporal_cat_in)\n",
    "        static_mask_in = torch.cat([sn_mask,sc_mask],dim=-1)\n",
    "        static_mask_e = self.static_mask(static_mask_in)\n",
    "        temporal_num_mask_e = self.temporal_num_mask_encoder(tn_mask)\n",
    "        temporal_cat_mask_e = self.temporal_cat_mask_encoder(tc_mask)\n",
    "        e = torch.cat([static_e,temporal_num_e,temporal_cat_e,static_mask_e,temporal_num_mask_e,temporal_cat_mask_e],dim=-1)\n",
    "        e = self.fusion(e)\n",
    "        return e\n",
    "\n",
    "\n",
    "    def decode(self, e, max_seq_len_num=100,max_seq_len_cat=300):\n",
    "        sn_hat = self.static_decoder_num(e)\n",
    "        sc_hat = self.static_decoder_cat(e)\n",
    "        static_mask_hat = self.static_decoder_mask(e)\n",
    "        sn_dim = sn_hat.shape[-1]\n",
    "        sn_mask_hat = static_mask_hat[..., :sn_dim]\n",
    "        sc_mask_hat = static_mask_hat[..., sn_dim:]\n",
    "        tn_hat, un_hat, tn_mask_hat, seq_len_num = self.temporal_decoder_num(e, max_seq_len_num)\n",
    "        tc_hat, uc_hat, tc_mask_hat, seq_len_cat = self.temporal_decoder_cat(e, max_seq_len_cat)\n",
    "        return sn_hat,sc_hat,tn_hat,tc_hat,un_hat,uc_hat,sn_mask_hat,sc_mask_hat,tn_mask_hat,tc_mask_hat,seq_len_num,seq_len_cat\n",
    "\n",
    "    def forward(self,sn,sc,tn,tc,un,uc,sn_mask,sc_mask,tn_mask,tc_mask,max_seq_len_num=None,max_seq_len_cat=None):\n",
    "        e = self.encode(sn,sc,tn,tc,un,uc,sn_mask,sc_mask,tn_mask,tc_mask)\n",
    "        if max_seq_len_num is None:\n",
    "            max_seq_len_num = tn.size(1)\n",
    "        if max_seq_len_cat is None:\n",
    "            max_seq_len_cat = tc.size(1)\n",
    "        return self.decode(e, max_seq_len_num,max_seq_len_cat)\n",
    "\n",
    "    def get_encoding(self, sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, as_numpy: bool = False):\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            inputs = [sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask]\n",
    "            inputs = [x.to(device) if torch.is_tensor(x) else x for x in inputs]\n",
    "            sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask = inputs\n",
    "            e = self.encode(sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask)\n",
    "            if as_numpy:\n",
    "                return e.detach().cpu().numpy()\n",
    "            return e\n",
    "    \n",
    "    def generate_decoding(self, e=None, batch_size=1, max_seq_len_num=100, max_seq_len_cat=300, device=\"cpu\", mask_threshold=0.5):\n",
    "        self.eval()\n",
    "        device = torch.device(device)\n",
    "        with torch.no_grad():\n",
    "            (sn_hat, sc_hat, tn_hat, tc_hat, un_hat, uc_hat, sn_mask_hat, sc_mask_hat, tn_mask_hat, tc_mask_hat, seq_len_num, seq_len_cat) = self.decode(e, max_seq_len_num, max_seq_len_cat)\n",
    "            \n",
    "            # Apply sigmoid + threshold for all masks\n",
    "            sn_mask_hat = torch.sigmoid(sn_mask_hat) > mask_threshold\n",
    "            sc_mask_hat = torch.sigmoid(sc_mask_hat) > mask_threshold\n",
    "            tn_mask_hat = torch.sigmoid(tn_mask_hat) > mask_threshold\n",
    "            tc_mask_hat = torch.sigmoid(tc_mask_hat) > mask_threshold\n",
    "    \n",
    "            # Slice sequences according to predicted lengths\n",
    "            tn_hat = [tn_hat[i, :seq_len_num[i]] for i in range(tn_hat.size(0))]\n",
    "            tc_hat = [tc_hat[i, :seq_len_cat[i]] for i in range(tc_hat.size(0))]\n",
    "            un_hat = [un_hat[i, :seq_len_num[i]] for i in range(un_hat.size(0))]\n",
    "            uc_hat = [uc_hat[i, :seq_len_cat[i]] for i in range(uc_hat.size(0))]\n",
    "            tn_mask_hat = [tn_mask_hat[i, :seq_len_num[i]] for i in range(tn_mask_hat.size(0))]\n",
    "            tc_mask_hat = [tc_mask_hat[i, :seq_len_cat[i]] for i in range(tc_mask_hat.size(0))]\n",
    "    \n",
    "        return (sn_hat, sc_hat, sn_mask_hat, sc_mask_hat, tn_hat, tc_hat, un_hat, uc_hat, tn_mask_hat, tc_mask_hat)\n",
    "\n",
    "    def compute_loss(\n",
    "        self, sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask,\n",
    "        sn_hat, sc_hat, sn_mask_hat, sc_mask_hat, tn_hat, tc_hat, un_hat, uc_hat,\n",
    "        tn_mask_hat, tc_mask_hat, pred_seq_len_num, pred_seq_len_cat, true_seq_len_num, true_seq_len_cat,\n",
    "        lambda_mse=1.0, lambda_len=0.1\n",
    "    ):\n",
    "        losses = {}\n",
    "        bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        mse = nn.MSELoss(reduction='none')\n",
    "        epsilon = 1e-8\n",
    "        device = sn.device\n",
    "        if not torch.is_tensor(pred_seq_len_num):\n",
    "            pred_seq_len_num = torch.tensor(pred_seq_len_num, device=device, dtype=torch.float32)\n",
    "        if pred_seq_len_num.dim() == 0:\n",
    "            pred_seq_len_num = pred_seq_len_num.unsqueeze(0)\n",
    "        if not torch.is_tensor(pred_seq_len_cat):\n",
    "            pred_seq_len_cat = torch.tensor(pred_seq_len_cat, device=device, dtype=torch.float32)\n",
    "        if pred_seq_len_cat.dim() == 0:\n",
    "            pred_seq_len_cat = pred_seq_len_cat.unsqueeze(0)\n",
    "        if not torch.is_tensor(true_seq_len_num):\n",
    "            true_seq_len_num = torch.tensor(true_seq_len_num, device=device, dtype=torch.float32)\n",
    "        if true_seq_len_num.dim() == 0:\n",
    "            true_seq_len_num = true_seq_len_num.unsqueeze(0)\n",
    "        if not torch.is_tensor(true_seq_len_cat):\n",
    "            true_seq_len_cat = torch.tensor(true_seq_len_cat, device=device, dtype=torch.float32)\n",
    "        if true_seq_len_cat.dim() == 0:\n",
    "            true_seq_len_cat = true_seq_len_cat.unsqueeze(0)\n",
    "        pred_len_num = tn_hat.size(1)\n",
    "        pred_len_cat = tc_hat.size(1)\n",
    "        tn_sliced = tn[:, :pred_len_num, :]\n",
    "        un_sliced = un[:, :pred_len_num].unsqueeze(-1)\n",
    "        tn_mask_sliced = tn_mask[:, :pred_len_num, :]\n",
    "        tc_sliced = tc[:, :pred_len_cat, :]\n",
    "        uc_sliced = uc[:, :pred_len_cat].unsqueeze(-1)\n",
    "        tc_mask_sliced = tc_mask[:, :pred_len_cat, :]\n",
    "        seq_mask_num = torch.arange(pred_len_num, device=device).unsqueeze(0) < pred_seq_len_num.unsqueeze(1)\n",
    "        seq_mask_num = seq_mask_num.unsqueeze(-1).float()\n",
    "        seq_mask_cat = torch.arange(pred_len_cat, device=device).unsqueeze(0) < pred_seq_len_cat.unsqueeze(1)\n",
    "        seq_mask_cat = seq_mask_cat.unsqueeze(-1).float()\n",
    "        losses[\"sn_mask\"] = bce(sn_mask_hat, sn_mask).mean()\n",
    "        losses[\"sc_mask\"] = bce(sc_mask_hat, sc_mask).mean()\n",
    "        tn_mask_loss = bce(tn_mask_hat, tn_mask_sliced).mean(dim=-1)\n",
    "        losses[\"tn_mask\"] = (tn_mask_loss * seq_mask_num[..., 0]).sum() / (seq_mask_num[..., 0].sum() + epsilon)\n",
    "        tc_mask_loss = bce(tc_mask_hat, tc_mask_sliced).mean(dim=-1)\n",
    "        losses[\"tc_mask\"] = (tc_mask_loss * seq_mask_cat[..., 0]).sum() / (seq_mask_cat[..., 0].sum() + epsilon)\n",
    "        losses[\"sn\"] = (mse(sn_hat, sn) * sn_mask).sum() / (sn_mask.sum() + epsilon)\n",
    "        losses[\"sc\"] = mse(sc_hat, sc).mean()\n",
    "        losses[\"tn\"] = (mse(tn_hat, tn_sliced) * tn_mask_sliced * seq_mask_num).sum() / ((tn_mask_sliced * seq_mask_num).sum() + epsilon)\n",
    "        losses[\"tc\"] = (mse(tc_hat, tc_sliced) * seq_mask_cat).sum() / (seq_mask_cat.sum() + epsilon)\n",
    "        losses[\"un\"] = (mse(un_hat, un_sliced) * seq_mask_num).sum() / (seq_mask_num.sum() + epsilon)\n",
    "        losses[\"uc\"] = (mse(uc_hat, uc_sliced) * seq_mask_cat).sum() / (seq_mask_cat.sum() + epsilon)\n",
    "        losses[\"len_num\"] = F.mse_loss(pred_seq_len_num.float(), true_seq_len_num.float())\n",
    "        losses[\"len_cat\"] = F.mse_loss(pred_seq_len_cat.float(), true_seq_len_cat.float())\n",
    "        total_loss = (\n",
    "            losses[\"sn_mask\"] + losses[\"sc_mask\"] +\n",
    "            losses[\"tn_mask\"] + losses[\"tc_mask\"] +\n",
    "            lambda_mse * (losses[\"sn\"] + losses[\"sc\"] + losses[\"tn\"] + losses[\"tc\"] + losses[\"un\"] + losses[\"uc\"]) +\n",
    "            lambda_len * (losses[\"len_num\"] + losses[\"len_cat\"])\n",
    "        )\n",
    "        return total_loss, losses\n",
    "\n",
    "    def fit(self, train_dataloader, val_dataloader=None, epochs=20, lr=1e-3, optimizer=\"adam\", \n",
    "            lambda_mse=1.0, lambda_len=0.1, device=\"cpu\",\n",
    "            scheduler_patience=5, scheduler_factor=0.1,resume_from=None):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        print(f\"Training on: {device}\")\n",
    "        if optimizer.lower() == \"adam\":\n",
    "            opt = optim.Adam(self.parameters(), lr=lr)\n",
    "        elif optimizer.lower() == \"rmsprop\":\n",
    "            opt = optim.RMSprop(self.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer must be 'adam' or 'rmsprop'\")\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=scheduler_patience, factor=scheduler_factor)\n",
    "        start_epoch = 1\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        if resume_from is not None:\n",
    "            start_epoch = self.load_checkpoint(resume_from, optimizer=opt, scheduler=scheduler)  \n",
    "\n",
    "        for epoch in range(start_epoch, epochs + 1):\n",
    "            self.train()\n",
    "            total_train_loss = 0.0\n",
    "            train_loss_components = {}\n",
    "            for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=False):\n",
    "                sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, true_seq_len_num, true_seq_len_cat = [\n",
    "                    x.to(device) if torch.is_tensor(x) else x for x in batch\n",
    "                ]\n",
    "                max_seq_len_num = tn.size(1)\n",
    "                max_seq_len_cat = tc.size(1)\n",
    "                (sn_hat,sc_hat,tn_hat,tc_hat,un_hat,uc_hat,sn_mask_hat,sc_mask_hat,tn_mask_hat,tc_mask_hat,pred_seq_len_num,pred_seq_len_cat) = self(\n",
    "                    sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, max_seq_len_num, max_seq_len_cat\n",
    "                )\n",
    "                loss, losses_dict = self.compute_loss(\n",
    "                    sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask,\n",
    "                    sn_hat, sc_hat, sn_mask_hat, sc_mask_hat, tn_hat, tc_hat, un_hat, uc_hat,\n",
    "                    tn_mask_hat, tc_mask_hat, pred_seq_len_num, pred_seq_len_cat,\n",
    "                    true_seq_len_num, true_seq_len_cat, lambda_mse=lambda_mse, lambda_len=lambda_len\n",
    "                )\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                total_train_loss += loss.item()\n",
    "                for k, v in losses_dict.items():\n",
    "                    train_loss_components[k] = train_loss_components.get(k, 0.0) + v.item()\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            avg_train_components = {k: v / len(train_dataloader) for k, v in train_loss_components.items()}\n",
    "            avg_val_loss = None\n",
    "            val_loss_components = {}\n",
    "            if val_dataloader is not None:\n",
    "                self.eval()\n",
    "                total_val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch}/{epochs} [Val]\", leave=False):\n",
    "                        sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, true_seq_len_num, true_seq_len_cat = [\n",
    "                            x.to(device) if torch.is_tensor(x) else x for x in batch\n",
    "                        ]\n",
    "                        max_seq_len_num = tn.size(1)\n",
    "                        max_seq_len_cat = tc.size(1)\n",
    "                        (sn_hat,sc_hat,tn_hat,tc_hat,un_hat,uc_hat,sn_mask_hat,sc_mask_hat,tn_mask_hat,tc_mask_hat,pred_seq_len_num,pred_seq_len_cat) = self(\n",
    "                            sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, max_seq_len_num, max_seq_len_cat)\n",
    "                        loss, losses_dict = self.compute_loss(\n",
    "                            sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask,\n",
    "                            sn_hat, sc_hat, sn_mask_hat, sc_mask_hat, tn_hat, tc_hat, un_hat, uc_hat,\n",
    "                            tn_mask_hat, tc_mask_hat, pred_seq_len_num, pred_seq_len_cat,\n",
    "                            true_seq_len_num, true_seq_len_cat, lambda_mse=lambda_mse, lambda_len=lambda_len\n",
    "                        )\n",
    "                        total_val_loss += loss.item()\n",
    "                        for k, v in losses_dict.items():\n",
    "                            val_loss_components[k] = val_loss_components.get(k, 0.0) + v.item()\n",
    "                avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "                avg_val_components = {k: v / len(val_dataloader) for k, v in val_loss_components.items()}\n",
    "                scheduler.step(avg_val_loss)\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    self.save_checkpoint(opt, scheduler, epoch, filename='best_encoder_decoder_ckpt.pt')\n",
    "                    \n",
    "            if avg_val_loss is not None:\n",
    "                print(f\"Epoch {epoch}/{epochs} - Train Loss: {avg_train_loss:.7f} | Val Loss: {avg_val_loss:.7f} | Train LenNum: {avg_train_components['len_num']:.6f} | Train LenCat: {avg_train_components['len_cat']:.6f} | Val LenNum: {avg_val_components['len_num']:.6f} | Val LenCat: {avg_val_components['len_cat']:.6f}\")\n",
    "            else:\n",
    "                scheduler.step(avg_train_loss)\n",
    "                print(f\"Epoch {epoch}/{epochs} - Train Loss: {avg_train_loss:.7f} | Train LenNum: {avg_train_components['len_num']:.6f} | Train LenCat: {avg_train_components['len_cat']:.6f}\")\n",
    "\n",
    "        self.save_checkpoint(opt, scheduler, epoch)\n",
    "\n",
    "    def save_checkpoint(self, optimizer, scheduler, epoch, filename=\"encoder_decoder_ckpt.pt\"):\n",
    "        checkpoint = {\n",
    "            \"model_state\": self.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"scheduler_state\": scheduler.state_dict() if scheduler is not None else None,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "        torch.save(checkpoint, filename)\n",
    "        print(f\"Checkpoint saved at epoch {epoch} -> {filename}\")\n",
    "\n",
    "    def load_checkpoint(self, filename=\"encoder_decoder_ckpt.pt\", optimizer=None, scheduler=None, map_location=None):\n",
    "        checkpoint = torch.load(filename, map_location=map_location)\n",
    "        self.load_state_dict(checkpoint[\"model_state\"])\n",
    "        if optimizer is not None:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        if scheduler is not None and checkpoint[\"scheduler_state\"] is not None:\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\"Resumed from checkpoint {filename}, starting at epoch {start_epoch}\")\n",
    "        return start_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sn_dim = static_num_tensor.shape[1]            \n",
    "sce_latent_dim = static_cat_list[0].shape[0]   \n",
    "tn_dim = tn_list[0].shape[1:][-1]                \n",
    "tce_latent_dim = tc_list[0].shape[1]          \n",
    "sc_dim = static_cat_mask_list[0].shape[-1]\n",
    "tc_dim = tc_mask_list[0].shape[-1]                      \n",
    "\n",
    "model = EncoderDecoder(sn_dim=sn_dim,sce_latent_dim=sce_latent_dim,tn_dim=tn_dim,\n",
    "        tce_latent_dim=tce_latent_dim,sc_dim=sc_dim,tc_dim=tc_dim,latent_dim=256)\n",
    "model.to(device)\n",
    "\n",
    "model.fit(train_loader, val_loader, epochs=50, lr=1e-4, optimizer=\"adam\", lambda_mse=2.0, \n",
    "          lambda_len=1.0,device=\"cuda\",resume_from='best_encoder_decoder_ckpt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode_dataloader(encoder, dataloader, device=None, as_numpy=False):\n",
    "    encoder.eval()\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder.to(device)\n",
    "\n",
    "    embeddings_list = []\n",
    "    seq_len_num_list = []\n",
    "    seq_len_cat_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, seq_len_num, seq_len_cat = [\n",
    "                x.to(device) if torch.is_tensor(x) else x for x in batch\n",
    "            ]\n",
    "            e = encoder.get_encoding(\n",
    "                sn, sc, tn, tc, un, uc, sn_mask, sc_mask, tn_mask, tc_mask, as_numpy=False\n",
    "            )\n",
    "            embeddings_list.append(e.cpu())\n",
    "\n",
    "            seq_len_num_list.append(seq_len_num.cpu())\n",
    "            seq_len_cat_list.append(seq_len_cat.cpu())\n",
    "            \n",
    "    embeddings = torch.cat(embeddings_list, dim=0)          \n",
    "    seq_len_num_all = torch.cat(seq_len_num_list, dim=0)    \n",
    "    seq_len_cat_all = torch.cat(seq_len_cat_list, dim=0)     \n",
    "\n",
    "    if as_numpy:\n",
    "        return embeddings.numpy(), {\n",
    "            \"seq_len_num\": seq_len_num_all.numpy(),\n",
    "            \"seq_len_cat\": seq_len_cat_all.numpy()\n",
    "        }\n",
    "    return embeddings, {\"seq_len_num\": seq_len_num_all, \"seq_len_cat\": seq_len_cat_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sn_dim = static_num_tensor.shape[1]            \n",
    "sce_latent_dim = static_cat_list[0].shape[0]   \n",
    "tn_dim = tn_list[0].shape[1:][-1]                \n",
    "tce_latent_dim = tc_list[0].shape[1]          \n",
    "sc_dim = static_cat_mask_list[0].shape[-1]\n",
    "tc_dim = tc_mask_list[0].shape[-1]                      \n",
    "encoder = EncoderDecoder(sn_dim=sn_dim,sce_latent_dim=sce_latent_dim,tn_dim=tn_dim,\n",
    "            tce_latent_dim=tce_latent_dim,sc_dim=sc_dim,tc_dim=tc_dim,latent_dim=256)\n",
    "encoder.load_checkpoint(filename=\"best_encoder_decoder_ckpt.pt\")\n",
    "encoder.to(device)\n",
    "emb_train, info_train = encode_dataloader(encoder, train_loader, device=device)\n",
    "emb_val, info_val = encode_dataloader(encoder, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(emb_train, \"encoder_embeddings_train.pt\")\n",
    "torch.save(emb_val, \"encoder_embeddings_val.pt\")\n",
    "torch.save(info_train, \"encoder_embeddings_info_train.pt\")\n",
    "torch.save(info_val, \"encoder_embeddings_info_val.pt\")\n",
    "print(\"Saved embeddings: train:\", emb_train.shape, \" val:\", emb_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat([emb_train, emb_val], dim=0)  \n",
    "torch.save(all_embeddings, \"encoder_embeddings_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat([emb_train, emb_val], dim=0)\n",
    "gan_dataset = TensorDataset(all_embeddings)\n",
    "dataset_size = len(gan_dataset)\n",
    "split_size = int(0.05 * dataset_size)\n",
    "train_dataset, val_dataset = random_split(gan_dataset, [dataset_size - split_size, split_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True,num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, drop_last=False,num_workers=4)\n",
    "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Shape of first batch:\", first_batch[0].shape)\n",
    "print(\"First 5 entries in the first batch:\")\n",
    "print(first_batch[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = torch.stack(first_batch) \n",
    "overall_mean = batch.mean().item()\n",
    "overall_std = batch.std().item()\n",
    "print(\"Overall mean:\", overall_mean)\n",
    "print(\"Overall std:\", overall_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7c35564",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,encoder_state_dim,latent_dim = 256,hidden_dims=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512,1024,2048,1024,512]\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = latent_dim\n",
    "\n",
    "        for i,hidden_dim in enumerate(hidden_dims):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim,hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(0.2 if i < len(hidden_dims)//2 else 0.1)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Linear(prev_dim,encoder_state_dim*2),\n",
    "            nn.BatchNorm1d(encoder_state_dim*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(encoder_state_dim*2,encoder_state_dim)\n",
    "        ])\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c974681",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,encoder_state_dim,hidden_dims = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256,512,1024,2048,1024,512,256,128]\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = encoder_state_dim\n",
    "\n",
    "        for i,hidden_dim in enumerate(hidden_dims):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim,hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(0.3 if i < len(hidden_dims)//2 else 0.2)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Linear(prev_dim,64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64,1)\n",
    "        ])\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_mmd(x, y, sigma=None):\n",
    "    if isinstance(x, list):\n",
    "        x = torch.stack(x)\n",
    "    if isinstance(y, list):\n",
    "        y = torch.stack(y)\n",
    "\n",
    "    x, y = x.to(torch.float32), y.to(torch.float32)\n",
    "\n",
    "    combined = torch.cat([x, y], dim=0)\n",
    "    mean = combined.mean(dim=0, keepdim=True)\n",
    "    std = combined.std(dim=0, keepdim=True) + 1e-6\n",
    "    x_norm = (x - mean) / std\n",
    "    y_norm = (y - mean) / std\n",
    "    if sigma is None:\n",
    "        xy = torch.cat([x_norm, y_norm], dim=0)\n",
    "        dists = torch.cdist(xy, xy, p=2)\n",
    "        sigma = torch.median(dists).item()\n",
    "        if sigma == 0:\n",
    "            sigma = 1.0\n",
    "\n",
    "    def gaussian_kernel(a, b, sigma):\n",
    "        dist_sq = torch.cdist(a, b, p=2) ** 2\n",
    "        return torch.exp(-dist_sq / (2 * sigma ** 2))\n",
    "\n",
    "    k_xx = gaussian_kernel(x_norm, x_norm, sigma)\n",
    "    k_yy = gaussian_kernel(y_norm, y_norm, sigma)\n",
    "    k_xy = gaussian_kernel(x_norm, y_norm, sigma)\n",
    "\n",
    "    mmd = k_xx.mean() + k_yy.mean() - 2 * k_xy.mean()\n",
    "    return mmd.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df8b0c53",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WGANGP:\n",
    "    def __init__(self, encoder_state_dim, latent_dim=128,\n",
    "                 generator_hidden_dims=None, discriminator_hidden_dims=None,\n",
    "                 lr_generator=1e-4, lr_discriminator=1e-4,\n",
    "                 lambda_gp=10.0, n_critic=5, device=None,\n",
    "                 plateau_factor=0.5, plateau_patience=10):\n",
    "\n",
    "        self.encoder_state_dim = encoder_state_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.n_critic = n_critic\n",
    "        self.device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "        self.generator = Generator(encoder_state_dim, latent_dim, generator_hidden_dims).to(self.device)\n",
    "        self.discriminator = Discriminator(encoder_state_dim, discriminator_hidden_dims).to(self.device)\n",
    "\n",
    "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=lr_generator, betas=(0.5, 0.9))\n",
    "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr_discriminator, betas=(0.5, 0.9))\n",
    "\n",
    "        # ReduceLROnPlateau scheduler\n",
    "        self.scheduler_G = ReduceLROnPlateau(self.optimizer_G, mode='min', factor=plateau_factor,\n",
    "                                             patience=plateau_patience)\n",
    "        self.scheduler_D = ReduceLROnPlateau(self.optimizer_D, mode='min', factor=plateau_factor,\n",
    "                                             patience=plateau_patience)\n",
    "\n",
    "        self.start_epoch = 1\n",
    "        self.best_mmd = float(\"inf\")\n",
    "\n",
    "    def gradient_penalty(self, real_samples, fake_samples):\n",
    "        real_samples = real_samples.to(self.device).float()\n",
    "        fake_samples = fake_samples.to(self.device).float()\n",
    "        batch_size = real_samples.size(0)\n",
    "        epsilon = torch.rand(batch_size, 1, device=self.device).expand_as(real_samples)\n",
    "        interpolated = epsilon * real_samples + (1 - epsilon) * fake_samples.detach()\n",
    "        interpolated.requires_grad_(True)\n",
    "\n",
    "        d_interpolated = self.discriminator(interpolated)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_interpolated,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones_like(d_interpolated, device=self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        gradient_penalty = self.lambda_gp * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def discriminator_loss(self, real_samples, fake_samples):\n",
    "        d_real = self.discriminator(real_samples)\n",
    "        d_fake = self.discriminator(fake_samples.detach())\n",
    "        wasserstein_distance = d_real.mean() - d_fake.mean()\n",
    "        gp = self.gradient_penalty(real_samples, fake_samples)\n",
    "        d_loss = -wasserstein_distance + gp\n",
    "        return d_loss, wasserstein_distance, gp\n",
    "\n",
    "    def generator_loss(self, fake_samples):\n",
    "        d_fake = self.discriminator(fake_samples)\n",
    "        g_loss = -d_fake.mean()\n",
    "        return g_loss\n",
    "\n",
    "    def generate_samples(self, batch_size):\n",
    "        z = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "        fake_samples = self.generator(z).float()\n",
    "        return fake_samples\n",
    "\n",
    "    def fit(self, train_dataloader, epochs=100, resume_from=None, \n",
    "            val_dataloader=None, verbose=True):\n",
    "\n",
    "        if resume_from:\n",
    "            self.load_checkpoint(resume_from)\n",
    "            print(f\"Resumed training from checkpoint: {resume_from}\")\n",
    "\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        history = {\n",
    "            \"train_d_loss\": [], \"train_g_loss\": [], \"train_wd\": [], \"train_gp\": [],\n",
    "            \"val_g_loss\": [], \"val_wd\": [], \"val_mmd\": []\n",
    "        }\n",
    "\n",
    "        for epoch in range(self.start_epoch, epochs + 1):\n",
    "            epoch_d_loss = epoch_g_loss = epoch_wd = epoch_gp = 0.0\n",
    "            batches = 0\n",
    "            progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch}/{epochs}') if verbose else train_dataloader\n",
    "\n",
    "            for i, (real_samples,) in enumerate(progress_bar):\n",
    "                batches += 1\n",
    "                real_samples = real_samples.to(self.device).float()\n",
    "                bsz = real_samples.size(0)\n",
    "\n",
    "                # ---- Train Discriminator ----\n",
    "                self.optimizer_D.zero_grad()\n",
    "                fake_samples = self.generate_samples(bsz)\n",
    "                d_loss, wd, gp = self.discriminator_loss(real_samples, fake_samples)\n",
    "                d_loss.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                epoch_d_loss += d_loss.item()\n",
    "                epoch_wd += wd.item()\n",
    "                epoch_gp += gp.item()\n",
    "\n",
    "                # ---- Train Generator every n_critic ----\n",
    "                if i % self.n_critic == 0:\n",
    "                    self.optimizer_G.zero_grad()\n",
    "                    fake_samples = self.generate_samples(bsz)\n",
    "                    g_loss = self.generator_loss(fake_samples)\n",
    "                    g_loss.backward()\n",
    "                    self.optimizer_G.step()\n",
    "                    epoch_g_loss += g_loss.item()\n",
    "\n",
    "            avg_d_loss = epoch_d_loss / batches\n",
    "            avg_g_loss = epoch_g_loss / max(1, (batches // self.n_critic))\n",
    "            avg_wd = epoch_wd / batches\n",
    "            avg_gp = epoch_gp / batches\n",
    "\n",
    "            history[\"train_d_loss\"].append(avg_d_loss)\n",
    "            history[\"train_g_loss\"].append(avg_g_loss)\n",
    "            history[\"train_wd\"].append(avg_wd)\n",
    "            history[\"train_gp\"].append(avg_gp)\n",
    "\n",
    "            # ---- Validation ----\n",
    "            if val_dataloader is not None:\n",
    "                self.generator.eval()\n",
    "                self.discriminator.eval()\n",
    "                real_embeddings, fake_embeddings = [], []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for real_samples, in val_dataloader:\n",
    "                        real_samples = real_samples.to(self.device).float()\n",
    "                        fake_samples = self.generate_samples(real_samples.size(0))\n",
    "                        real_embeddings.append(real_samples)\n",
    "                        fake_embeddings.append(fake_samples)\n",
    "\n",
    "                real_embeddings = torch.cat(real_embeddings, dim=0)\n",
    "                fake_embeddings = torch.cat(fake_embeddings, dim=0)\n",
    "                current_mmd = compute_mmd(real_embeddings, fake_embeddings)\n",
    "                history[\"val_mmd\"].append(current_mmd)\n",
    "\n",
    "                val_g_loss = val_wd = 0.0\n",
    "                val_batches = 0\n",
    "                with torch.no_grad():\n",
    "                    for real_samples, in val_dataloader:\n",
    "                        val_batches += 1\n",
    "                        real_samples = real_samples.to(self.device).float()\n",
    "                        bsz = real_samples.size(0)\n",
    "                        fake_samples = self.generate_samples(bsz)\n",
    "\n",
    "                        d_real = self.discriminator(real_samples)\n",
    "                        d_fake = self.discriminator(fake_samples)\n",
    "\n",
    "                        wd = d_real.mean() - d_fake.mean()\n",
    "                        g_loss = self.generator_loss(fake_samples)\n",
    "                        val_g_loss += g_loss.item()\n",
    "                        val_wd += wd.item()\n",
    "\n",
    "                avg_val_g_loss = val_g_loss / val_batches\n",
    "                avg_val_wd = val_wd / val_batches\n",
    "\n",
    "                history[\"val_g_loss\"].append(avg_val_g_loss)\n",
    "                history[\"val_wd\"].append(avg_val_wd)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[Epoch {epoch}] Train D: {avg_d_loss:.7f}, G: {avg_g_loss:.7f}, WD: {avg_wd:.7f}, GP: {avg_gp:.7f} | \"\n",
    "                          f\"Val WD: {avg_val_wd:.7f}, MMD: {current_mmd:.7f}\")\n",
    "\n",
    "                # Save best model\n",
    "                if current_mmd < self.best_mmd:\n",
    "                    self.best_mmd = current_mmd\n",
    "                    self.save_checkpoint(\"best_gan.pt\", epoch, history, is_best=True)\n",
    "\n",
    "                self.generator.train()\n",
    "                self.discriminator.train()\n",
    "\n",
    "                # ---- Step scheduler using validation MMD ----\n",
    "                self.scheduler_G.step(current_mmd)\n",
    "                self.scheduler_D.step(current_mmd)\n",
    "\n",
    "            else:\n",
    "                if avg_wd > getattr(self, \"best_wd\", float(\"-inf\")):\n",
    "                    self.best_wd = avg_wd\n",
    "                    self.save_checkpoint(\"best_gan.pt\", epoch, history, is_best=True)\n",
    "\n",
    "        self.save_checkpoint(\"final_gan.pt\", epoch, history)\n",
    "        print(\"Training completed!\")\n",
    "        return history\n",
    "\n",
    "    def save_checkpoint(self, filename, epoch, history, is_best=False):\n",
    "        state = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"generator_state\": self.generator.state_dict(),\n",
    "            \"discriminator_state\": self.discriminator.state_dict(),\n",
    "            \"optimizer_G\": self.optimizer_G.state_dict(),\n",
    "            \"optimizer_D\": self.optimizer_D.state_dict(),\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"encoder_state_dim\": self.encoder_state_dim,\n",
    "            \"best_mmd\": self.best_mmd,\n",
    "            \"history\": history\n",
    "        }\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            print(f\"Best model saved at {filename} (MMD: {self.best_mmd:.7f})\")\n",
    "        else:\n",
    "            print(f\"Checkpoint saved at {filename}\")\n",
    "\n",
    "    def load_checkpoint(self, filename, map_location=None):\n",
    "        checkpoint = torch.load(filename, map_location=map_location or self.device)\n",
    "        self.generator.load_state_dict(checkpoint[\"generator_state\"])\n",
    "        self.discriminator.load_state_dict(checkpoint[\"discriminator_state\"])\n",
    "        self.optimizer_G.load_state_dict(checkpoint[\"optimizer_G\"])\n",
    "        self.optimizer_D.load_state_dict(checkpoint[\"optimizer_D\"])\n",
    "        self.generator.to(self.device)\n",
    "        self.discriminator.to(self.device)\n",
    "        self.start_epoch = checkpoint[\"epoch\"]\n",
    "        self.best_mmd = checkpoint.get(\"best_mmd\", float(\"inf\"))\n",
    "        print(f\"Checkpoint loaded: {filename} (resuming at epoch {self.start_epoch})\")\n",
    "        return checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e173ebbe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wgan = WGANGP(encoder_state_dim=256,latent_dim=256)\n",
    "history = wgan.fit(\n",
    "    train_dataloader=train_loader,   \n",
    "    epochs=200,\n",
    "    val_dataloader=val_loader,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpuV5e8",
   "dataSources": [
    {
     "datasetId": 8355526,
     "sourceId": 13185185,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8358585,
     "sourceId": 13189728,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8371346,
     "sourceId": 13208115,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8371620,
     "sourceId": 13208495,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8377572,
     "sourceId": 13217191,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8432968,
     "sourceId": 13304067,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
